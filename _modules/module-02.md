---
title: Representation learning 
---

Oct 09
: [Pretraining and finetuning (basics)](https://nyu-cs2590.github.io/course-material/fall2024/lecture/lec06/main.pdf) [[recording]]
  : **HW 2 due**{: .label .label-red }
    **HW 3 out**{: .label .label-green} [HW3 zip](https://github.com/nyu-cs2590/course-material/blob/gh-pages/fall2024/assignment/hw3/hw3.zip?raw=true) [[pdf]](https://nyu-cs2590.github.io/course-material/fall2024/assignment/hw3/hw3.pdf)

: - Self-supervised learning
  - Encoder-only, decoder-only, encoder-decoder models

Oct 10           
: **Section**{: .label .label-purple } Huggingface Transformer [Sec06 notebook](https://github.com/nyu-cs2590/course-material/blob/gh-pages/fall2024/section/sec06/sec06.ipynb) [Sec06 slides](https://github.com/nyu-cs2590/course-material/blob/gh-pages/fall2024/section/sec06/sec06.pdf)

Oct 16
: [Pretraining and finetuning (advanced)](https://nyu-cs2590.github.io/course-material/fall2024/lecture/lec07/main.pdf) [[recording]]
  : **Proposal due**{: .label .label-red }
: - Sub-word tokenization 
  - Efficient pre-training 
  - Parameter efficient finetuning 

Oct 17           
: **Section**{: .label .label-purple } [Mixed-precision training, efficient inference](https://github.com/nyu-cs2590/course-material/blob/gh-pages/fall2024/section/sec07/Efficient_Inference_Student_copy.pdf)
