---
title: Representation learning 
---

Oct 09
: [Pretraining and finetuning (basics)]() [[recording]]
  : **HW 2 due**{: .label .label-red }
    **HW 3 out**{: .label .label-green} 
: - Self-supervised learning
  - Encoder-only, decoder-only, encoder-decoder models
  - Adaptation / finetuning  [HW3](https://github.com/nyu-cs2590/course-material/blob/gh-pages/fall2024/assignment/hw3/hw3.zip?raw=true) [[pdf]](https://nyu-cs2590.github.io/course-material/fall2024/assignment/hw3/hw3.pdf)

Oct 10           
: **Section**{: .label .label-purple } Huggingface Transformer

Oct 16
: [Pretraining and finetuning (advanced)]() [[recording]]
  : **Proposal due**{: .label .label-red }
: - Sub-word tokenization 
  - Optimization algorithms
  - Mixed-precision training
  - Parameter efficient finetuning 

Oct 17           
: **Section**{: .label .label-purple } Position encoding 
